/* This file is autogenerated by tracetool, do not edit. */

#ifndef TRACE_HW_VIRTIO_GENERATED_TRACERS_H
#define TRACE_HW_VIRTIO_GENERATED_TRACERS_H

#include "trace/control.h"

extern TraceEvent _TRACE_VHOST_COMMIT_EVENT;
extern TraceEvent _TRACE_VHOST_REGION_ADD_SECTION_EVENT;
extern TraceEvent _TRACE_VHOST_REGION_ADD_SECTION_MERGE_EVENT;
extern TraceEvent _TRACE_VHOST_REGION_ADD_SECTION_ALIGNED_EVENT;
extern TraceEvent _TRACE_VHOST_SECTION_EVENT;
extern TraceEvent _TRACE_VHOST_IOTLB_MISS_EVENT;
extern TraceEvent _TRACE_VHOST_USER_POSTCOPY_END_ENTRY_EVENT;
extern TraceEvent _TRACE_VHOST_USER_POSTCOPY_END_EXIT_EVENT;
extern TraceEvent _TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_EVENT;
extern TraceEvent _TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_LOOP_EVENT;
extern TraceEvent _TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_FOUND_EVENT;
extern TraceEvent _TRACE_VHOST_USER_POSTCOPY_LISTEN_EVENT;
extern TraceEvent _TRACE_VHOST_USER_SET_MEM_TABLE_POSTCOPY_EVENT;
extern TraceEvent _TRACE_VHOST_USER_SET_MEM_TABLE_WITHFD_EVENT;
extern TraceEvent _TRACE_VHOST_USER_POSTCOPY_WAKER_EVENT;
extern TraceEvent _TRACE_VHOST_USER_POSTCOPY_WAKER_FOUND_EVENT;
extern TraceEvent _TRACE_VHOST_USER_POSTCOPY_WAKER_NOMATCH_EVENT;
extern TraceEvent _TRACE_VIRTQUEUE_ALLOC_ELEMENT_EVENT;
extern TraceEvent _TRACE_VIRTQUEUE_FILL_EVENT;
extern TraceEvent _TRACE_VIRTQUEUE_FLUSH_EVENT;
extern TraceEvent _TRACE_VIRTQUEUE_POP_EVENT;
extern TraceEvent _TRACE_VIRTIO_QUEUE_NOTIFY_EVENT;
extern TraceEvent _TRACE_VIRTIO_NOTIFY_IRQFD_EVENT;
extern TraceEvent _TRACE_VIRTIO_NOTIFY_EVENT;
extern TraceEvent _TRACE_VIRTIO_SET_STATUS_EVENT;
extern TraceEvent _TRACE_VIRTIO_RNG_GUEST_NOT_READY_EVENT;
extern TraceEvent _TRACE_VIRTIO_RNG_CPU_IS_STOPPED_EVENT;
extern TraceEvent _TRACE_VIRTIO_RNG_POPPED_EVENT;
extern TraceEvent _TRACE_VIRTIO_RNG_PUSHED_EVENT;
extern TraceEvent _TRACE_VIRTIO_RNG_REQUEST_EVENT;
extern TraceEvent _TRACE_VIRTIO_RNG_VM_STATE_CHANGE_EVENT;
extern TraceEvent _TRACE_VIRTIO_BALLOON_BAD_ADDR_EVENT;
extern TraceEvent _TRACE_VIRTIO_BALLOON_HANDLE_OUTPUT_EVENT;
extern TraceEvent _TRACE_VIRTIO_BALLOON_GET_CONFIG_EVENT;
extern TraceEvent _TRACE_VIRTIO_BALLOON_SET_CONFIG_EVENT;
extern TraceEvent _TRACE_VIRTIO_BALLOON_TO_TARGET_EVENT;
extern TraceEvent _TRACE_VIRTIO_MMIO_READ_EVENT;
extern TraceEvent _TRACE_VIRTIO_MMIO_WRITE_OFFSET_EVENT;
extern TraceEvent _TRACE_VIRTIO_MMIO_GUEST_PAGE_EVENT;
extern TraceEvent _TRACE_VIRTIO_MMIO_QUEUE_WRITE_EVENT;
extern TraceEvent _TRACE_VIRTIO_MMIO_SETTING_IRQ_EVENT;
extern uint16_t _TRACE_VHOST_COMMIT_DSTATE;
extern uint16_t _TRACE_VHOST_REGION_ADD_SECTION_DSTATE;
extern uint16_t _TRACE_VHOST_REGION_ADD_SECTION_MERGE_DSTATE;
extern uint16_t _TRACE_VHOST_REGION_ADD_SECTION_ALIGNED_DSTATE;
extern uint16_t _TRACE_VHOST_SECTION_DSTATE;
extern uint16_t _TRACE_VHOST_IOTLB_MISS_DSTATE;
extern uint16_t _TRACE_VHOST_USER_POSTCOPY_END_ENTRY_DSTATE;
extern uint16_t _TRACE_VHOST_USER_POSTCOPY_END_EXIT_DSTATE;
extern uint16_t _TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_DSTATE;
extern uint16_t _TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_LOOP_DSTATE;
extern uint16_t _TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_FOUND_DSTATE;
extern uint16_t _TRACE_VHOST_USER_POSTCOPY_LISTEN_DSTATE;
extern uint16_t _TRACE_VHOST_USER_SET_MEM_TABLE_POSTCOPY_DSTATE;
extern uint16_t _TRACE_VHOST_USER_SET_MEM_TABLE_WITHFD_DSTATE;
extern uint16_t _TRACE_VHOST_USER_POSTCOPY_WAKER_DSTATE;
extern uint16_t _TRACE_VHOST_USER_POSTCOPY_WAKER_FOUND_DSTATE;
extern uint16_t _TRACE_VHOST_USER_POSTCOPY_WAKER_NOMATCH_DSTATE;
extern uint16_t _TRACE_VIRTQUEUE_ALLOC_ELEMENT_DSTATE;
extern uint16_t _TRACE_VIRTQUEUE_FILL_DSTATE;
extern uint16_t _TRACE_VIRTQUEUE_FLUSH_DSTATE;
extern uint16_t _TRACE_VIRTQUEUE_POP_DSTATE;
extern uint16_t _TRACE_VIRTIO_QUEUE_NOTIFY_DSTATE;
extern uint16_t _TRACE_VIRTIO_NOTIFY_IRQFD_DSTATE;
extern uint16_t _TRACE_VIRTIO_NOTIFY_DSTATE;
extern uint16_t _TRACE_VIRTIO_SET_STATUS_DSTATE;
extern uint16_t _TRACE_VIRTIO_RNG_GUEST_NOT_READY_DSTATE;
extern uint16_t _TRACE_VIRTIO_RNG_CPU_IS_STOPPED_DSTATE;
extern uint16_t _TRACE_VIRTIO_RNG_POPPED_DSTATE;
extern uint16_t _TRACE_VIRTIO_RNG_PUSHED_DSTATE;
extern uint16_t _TRACE_VIRTIO_RNG_REQUEST_DSTATE;
extern uint16_t _TRACE_VIRTIO_RNG_VM_STATE_CHANGE_DSTATE;
extern uint16_t _TRACE_VIRTIO_BALLOON_BAD_ADDR_DSTATE;
extern uint16_t _TRACE_VIRTIO_BALLOON_HANDLE_OUTPUT_DSTATE;
extern uint16_t _TRACE_VIRTIO_BALLOON_GET_CONFIG_DSTATE;
extern uint16_t _TRACE_VIRTIO_BALLOON_SET_CONFIG_DSTATE;
extern uint16_t _TRACE_VIRTIO_BALLOON_TO_TARGET_DSTATE;
extern uint16_t _TRACE_VIRTIO_MMIO_READ_DSTATE;
extern uint16_t _TRACE_VIRTIO_MMIO_WRITE_OFFSET_DSTATE;
extern uint16_t _TRACE_VIRTIO_MMIO_GUEST_PAGE_DSTATE;
extern uint16_t _TRACE_VIRTIO_MMIO_QUEUE_WRITE_DSTATE;
extern uint16_t _TRACE_VIRTIO_MMIO_SETTING_IRQ_DSTATE;
#define TRACE_VHOST_COMMIT_ENABLED 1
#define TRACE_VHOST_REGION_ADD_SECTION_ENABLED 1
#define TRACE_VHOST_REGION_ADD_SECTION_MERGE_ENABLED 1
#define TRACE_VHOST_REGION_ADD_SECTION_ALIGNED_ENABLED 1
#define TRACE_VHOST_SECTION_ENABLED 1
#define TRACE_VHOST_IOTLB_MISS_ENABLED 1
#define TRACE_VHOST_USER_POSTCOPY_END_ENTRY_ENABLED 1
#define TRACE_VHOST_USER_POSTCOPY_END_EXIT_ENABLED 1
#define TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_ENABLED 1
#define TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_LOOP_ENABLED 1
#define TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_FOUND_ENABLED 1
#define TRACE_VHOST_USER_POSTCOPY_LISTEN_ENABLED 1
#define TRACE_VHOST_USER_SET_MEM_TABLE_POSTCOPY_ENABLED 1
#define TRACE_VHOST_USER_SET_MEM_TABLE_WITHFD_ENABLED 1
#define TRACE_VHOST_USER_POSTCOPY_WAKER_ENABLED 1
#define TRACE_VHOST_USER_POSTCOPY_WAKER_FOUND_ENABLED 1
#define TRACE_VHOST_USER_POSTCOPY_WAKER_NOMATCH_ENABLED 1
#define TRACE_VIRTQUEUE_ALLOC_ELEMENT_ENABLED 1
#define TRACE_VIRTQUEUE_FILL_ENABLED 1
#define TRACE_VIRTQUEUE_FLUSH_ENABLED 1
#define TRACE_VIRTQUEUE_POP_ENABLED 1
#define TRACE_VIRTIO_QUEUE_NOTIFY_ENABLED 1
#define TRACE_VIRTIO_NOTIFY_IRQFD_ENABLED 1
#define TRACE_VIRTIO_NOTIFY_ENABLED 1
#define TRACE_VIRTIO_SET_STATUS_ENABLED 1
#define TRACE_VIRTIO_RNG_GUEST_NOT_READY_ENABLED 1
#define TRACE_VIRTIO_RNG_CPU_IS_STOPPED_ENABLED 1
#define TRACE_VIRTIO_RNG_POPPED_ENABLED 1
#define TRACE_VIRTIO_RNG_PUSHED_ENABLED 1
#define TRACE_VIRTIO_RNG_REQUEST_ENABLED 1
#define TRACE_VIRTIO_RNG_VM_STATE_CHANGE_ENABLED 1
#define TRACE_VIRTIO_BALLOON_BAD_ADDR_ENABLED 1
#define TRACE_VIRTIO_BALLOON_HANDLE_OUTPUT_ENABLED 1
#define TRACE_VIRTIO_BALLOON_GET_CONFIG_ENABLED 1
#define TRACE_VIRTIO_BALLOON_SET_CONFIG_ENABLED 1
#define TRACE_VIRTIO_BALLOON_TO_TARGET_ENABLED 1
#define TRACE_VIRTIO_MMIO_READ_ENABLED 1
#define TRACE_VIRTIO_MMIO_WRITE_OFFSET_ENABLED 1
#define TRACE_VIRTIO_MMIO_GUEST_PAGE_ENABLED 1
#define TRACE_VIRTIO_MMIO_QUEUE_WRITE_ENABLED 1
#define TRACE_VIRTIO_MMIO_SETTING_IRQ_ENABLED 1
#include "qemu/log-for-trace.h"


#define TRACE_VHOST_COMMIT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_COMMIT) || \
    false)

static inline void _nocheck__trace_vhost_commit(bool started, bool changed)
{
    if (trace_event_get_state(TRACE_VHOST_COMMIT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_commit " "Started: %d Changed: %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , started, changed);
    }
}

static inline void trace_vhost_commit(bool started, bool changed)
{
    if (true) {
        _nocheck__trace_vhost_commit(started, changed);
    }
}

#define TRACE_VHOST_REGION_ADD_SECTION_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_REGION_ADD_SECTION) || \
    false)

static inline void _nocheck__trace_vhost_region_add_section(const char * name, uint64_t gpa, uint64_t size, uint64_t host)
{
    if (trace_event_get_state(TRACE_VHOST_REGION_ADD_SECTION) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_region_add_section " "%s: 0x%"PRIx64"+0x%"PRIx64" @ 0x%"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , name, gpa, size, host);
    }
}

static inline void trace_vhost_region_add_section(const char * name, uint64_t gpa, uint64_t size, uint64_t host)
{
    if (true) {
        _nocheck__trace_vhost_region_add_section(name, gpa, size, host);
    }
}

#define TRACE_VHOST_REGION_ADD_SECTION_MERGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_REGION_ADD_SECTION_MERGE) || \
    false)

static inline void _nocheck__trace_vhost_region_add_section_merge(const char * name, uint64_t new_size, uint64_t gpa, uint64_t owr)
{
    if (trace_event_get_state(TRACE_VHOST_REGION_ADD_SECTION_MERGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_region_add_section_merge " "%s: size: 0x%"PRIx64 " gpa: 0x%"PRIx64 " owr: 0x%"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , name, new_size, gpa, owr);
    }
}

static inline void trace_vhost_region_add_section_merge(const char * name, uint64_t new_size, uint64_t gpa, uint64_t owr)
{
    if (true) {
        _nocheck__trace_vhost_region_add_section_merge(name, new_size, gpa, owr);
    }
}

#define TRACE_VHOST_REGION_ADD_SECTION_ALIGNED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_REGION_ADD_SECTION_ALIGNED) || \
    false)

static inline void _nocheck__trace_vhost_region_add_section_aligned(const char * name, uint64_t gpa, uint64_t size, uint64_t host)
{
    if (trace_event_get_state(TRACE_VHOST_REGION_ADD_SECTION_ALIGNED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_region_add_section_aligned " "%s: 0x%"PRIx64"+0x%"PRIx64" @ 0x%"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , name, gpa, size, host);
    }
}

static inline void trace_vhost_region_add_section_aligned(const char * name, uint64_t gpa, uint64_t size, uint64_t host)
{
    if (true) {
        _nocheck__trace_vhost_region_add_section_aligned(name, gpa, size, host);
    }
}

#define TRACE_VHOST_SECTION_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_SECTION) || \
    false)

static inline void _nocheck__trace_vhost_section(const char * name, int r)
{
    if (trace_event_get_state(TRACE_VHOST_SECTION) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_section " "%s:%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , name, r);
    }
}

static inline void trace_vhost_section(const char * name, int r)
{
    if (true) {
        _nocheck__trace_vhost_section(name, r);
    }
}

#define TRACE_VHOST_IOTLB_MISS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_IOTLB_MISS) || \
    false)

static inline void _nocheck__trace_vhost_iotlb_miss(void * dev, int step)
{
    if (trace_event_get_state(TRACE_VHOST_IOTLB_MISS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_iotlb_miss " "%p step %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , dev, step);
    }
}

static inline void trace_vhost_iotlb_miss(void * dev, int step)
{
    if (true) {
        _nocheck__trace_vhost_iotlb_miss(dev, step);
    }
}

#define TRACE_VHOST_USER_POSTCOPY_END_ENTRY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_USER_POSTCOPY_END_ENTRY) || \
    false)

static inline void _nocheck__trace_vhost_user_postcopy_end_entry(void)
{
    if (trace_event_get_state(TRACE_VHOST_USER_POSTCOPY_END_ENTRY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_user_postcopy_end_entry " "" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_vhost_user_postcopy_end_entry(void)
{
    if (true) {
        _nocheck__trace_vhost_user_postcopy_end_entry();
    }
}

#define TRACE_VHOST_USER_POSTCOPY_END_EXIT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_USER_POSTCOPY_END_EXIT) || \
    false)

static inline void _nocheck__trace_vhost_user_postcopy_end_exit(void)
{
    if (trace_event_get_state(TRACE_VHOST_USER_POSTCOPY_END_EXIT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_user_postcopy_end_exit " "" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_vhost_user_postcopy_end_exit(void)
{
    if (true) {
        _nocheck__trace_vhost_user_postcopy_end_exit();
    }
}

#define TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER) || \
    false)

static inline void _nocheck__trace_vhost_user_postcopy_fault_handler(const char * name, uint64_t fault_address, int nregions)
{
    if (trace_event_get_state(TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_user_postcopy_fault_handler " "%s: @0x%"PRIx64" nregions:%d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , name, fault_address, nregions);
    }
}

static inline void trace_vhost_user_postcopy_fault_handler(const char * name, uint64_t fault_address, int nregions)
{
    if (true) {
        _nocheck__trace_vhost_user_postcopy_fault_handler(name, fault_address, nregions);
    }
}

#define TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_LOOP_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_LOOP) || \
    false)

static inline void _nocheck__trace_vhost_user_postcopy_fault_handler_loop(int i, uint64_t client_base, uint64_t size)
{
    if (trace_event_get_state(TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_LOOP) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_user_postcopy_fault_handler_loop " "%d: client 0x%"PRIx64" +0x%"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , i, client_base, size);
    }
}

static inline void trace_vhost_user_postcopy_fault_handler_loop(int i, uint64_t client_base, uint64_t size)
{
    if (true) {
        _nocheck__trace_vhost_user_postcopy_fault_handler_loop(i, client_base, size);
    }
}

#define TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_FOUND_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_FOUND) || \
    false)

static inline void _nocheck__trace_vhost_user_postcopy_fault_handler_found(int i, uint64_t region_offset, uint64_t rb_offset)
{
    if (trace_event_get_state(TRACE_VHOST_USER_POSTCOPY_FAULT_HANDLER_FOUND) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_user_postcopy_fault_handler_found " "%d: region_offset: 0x%"PRIx64" rb_offset:0x%"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , i, region_offset, rb_offset);
    }
}

static inline void trace_vhost_user_postcopy_fault_handler_found(int i, uint64_t region_offset, uint64_t rb_offset)
{
    if (true) {
        _nocheck__trace_vhost_user_postcopy_fault_handler_found(i, region_offset, rb_offset);
    }
}

#define TRACE_VHOST_USER_POSTCOPY_LISTEN_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_USER_POSTCOPY_LISTEN) || \
    false)

static inline void _nocheck__trace_vhost_user_postcopy_listen(void)
{
    if (trace_event_get_state(TRACE_VHOST_USER_POSTCOPY_LISTEN) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_user_postcopy_listen " "" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 );
    }
}

static inline void trace_vhost_user_postcopy_listen(void)
{
    if (true) {
        _nocheck__trace_vhost_user_postcopy_listen();
    }
}

#define TRACE_VHOST_USER_SET_MEM_TABLE_POSTCOPY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_USER_SET_MEM_TABLE_POSTCOPY) || \
    false)

static inline void _nocheck__trace_vhost_user_set_mem_table_postcopy(uint64_t client_addr, uint64_t qhva, int reply_i, int region_i)
{
    if (trace_event_get_state(TRACE_VHOST_USER_SET_MEM_TABLE_POSTCOPY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_user_set_mem_table_postcopy " "client:0x%"PRIx64" for hva: 0x%"PRIx64" reply %d region %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , client_addr, qhva, reply_i, region_i);
    }
}

static inline void trace_vhost_user_set_mem_table_postcopy(uint64_t client_addr, uint64_t qhva, int reply_i, int region_i)
{
    if (true) {
        _nocheck__trace_vhost_user_set_mem_table_postcopy(client_addr, qhva, reply_i, region_i);
    }
}

#define TRACE_VHOST_USER_SET_MEM_TABLE_WITHFD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_USER_SET_MEM_TABLE_WITHFD) || \
    false)

static inline void _nocheck__trace_vhost_user_set_mem_table_withfd(int index, const char * name, uint64_t memory_size, uint64_t guest_phys_addr, uint64_t userspace_addr, uint64_t offset)
{
    if (trace_event_get_state(TRACE_VHOST_USER_SET_MEM_TABLE_WITHFD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_user_set_mem_table_withfd " "%d:%s: size:0x%"PRIx64" GPA:0x%"PRIx64" QVA/userspace:0x%"PRIx64" RB offset:0x%"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , index, name, memory_size, guest_phys_addr, userspace_addr, offset);
    }
}

static inline void trace_vhost_user_set_mem_table_withfd(int index, const char * name, uint64_t memory_size, uint64_t guest_phys_addr, uint64_t userspace_addr, uint64_t offset)
{
    if (true) {
        _nocheck__trace_vhost_user_set_mem_table_withfd(index, name, memory_size, guest_phys_addr, userspace_addr, offset);
    }
}

#define TRACE_VHOST_USER_POSTCOPY_WAKER_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_USER_POSTCOPY_WAKER) || \
    false)

static inline void _nocheck__trace_vhost_user_postcopy_waker(const char * rb, uint64_t rb_offset)
{
    if (trace_event_get_state(TRACE_VHOST_USER_POSTCOPY_WAKER) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_user_postcopy_waker " "%s + 0x%"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , rb, rb_offset);
    }
}

static inline void trace_vhost_user_postcopy_waker(const char * rb, uint64_t rb_offset)
{
    if (true) {
        _nocheck__trace_vhost_user_postcopy_waker(rb, rb_offset);
    }
}

#define TRACE_VHOST_USER_POSTCOPY_WAKER_FOUND_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_USER_POSTCOPY_WAKER_FOUND) || \
    false)

static inline void _nocheck__trace_vhost_user_postcopy_waker_found(uint64_t client_addr)
{
    if (trace_event_get_state(TRACE_VHOST_USER_POSTCOPY_WAKER_FOUND) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_user_postcopy_waker_found " "0x%"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , client_addr);
    }
}

static inline void trace_vhost_user_postcopy_waker_found(uint64_t client_addr)
{
    if (true) {
        _nocheck__trace_vhost_user_postcopy_waker_found(client_addr);
    }
}

#define TRACE_VHOST_USER_POSTCOPY_WAKER_NOMATCH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VHOST_USER_POSTCOPY_WAKER_NOMATCH) || \
    false)

static inline void _nocheck__trace_vhost_user_postcopy_waker_nomatch(const char * rb, uint64_t rb_offset)
{
    if (trace_event_get_state(TRACE_VHOST_USER_POSTCOPY_WAKER_NOMATCH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:vhost_user_postcopy_waker_nomatch " "%s + 0x%"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , rb, rb_offset);
    }
}

static inline void trace_vhost_user_postcopy_waker_nomatch(const char * rb, uint64_t rb_offset)
{
    if (true) {
        _nocheck__trace_vhost_user_postcopy_waker_nomatch(rb, rb_offset);
    }
}

#define TRACE_VIRTQUEUE_ALLOC_ELEMENT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTQUEUE_ALLOC_ELEMENT) || \
    false)

static inline void _nocheck__trace_virtqueue_alloc_element(void * elem, size_t sz, unsigned in_num, unsigned out_num)
{
    if (trace_event_get_state(TRACE_VIRTQUEUE_ALLOC_ELEMENT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtqueue_alloc_element " "elem %p size %zd in_num %u out_num %u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , elem, sz, in_num, out_num);
    }
}

static inline void trace_virtqueue_alloc_element(void * elem, size_t sz, unsigned in_num, unsigned out_num)
{
    if (true) {
        _nocheck__trace_virtqueue_alloc_element(elem, sz, in_num, out_num);
    }
}

#define TRACE_VIRTQUEUE_FILL_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTQUEUE_FILL) || \
    false)

static inline void _nocheck__trace_virtqueue_fill(void * vq, const void * elem, unsigned int len, unsigned int idx)
{
    if (trace_event_get_state(TRACE_VIRTQUEUE_FILL) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtqueue_fill " "vq %p elem %p len %u idx %u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vq, elem, len, idx);
    }
}

static inline void trace_virtqueue_fill(void * vq, const void * elem, unsigned int len, unsigned int idx)
{
    if (true) {
        _nocheck__trace_virtqueue_fill(vq, elem, len, idx);
    }
}

#define TRACE_VIRTQUEUE_FLUSH_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTQUEUE_FLUSH) || \
    false)

static inline void _nocheck__trace_virtqueue_flush(void * vq, unsigned int count)
{
    if (trace_event_get_state(TRACE_VIRTQUEUE_FLUSH) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtqueue_flush " "vq %p count %u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vq, count);
    }
}

static inline void trace_virtqueue_flush(void * vq, unsigned int count)
{
    if (true) {
        _nocheck__trace_virtqueue_flush(vq, count);
    }
}

#define TRACE_VIRTQUEUE_POP_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTQUEUE_POP) || \
    false)

static inline void _nocheck__trace_virtqueue_pop(void * vq, void * elem, unsigned int in_num, unsigned int out_num)
{
    if (trace_event_get_state(TRACE_VIRTQUEUE_POP) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtqueue_pop " "vq %p elem %p in_num %u out_num %u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vq, elem, in_num, out_num);
    }
}

static inline void trace_virtqueue_pop(void * vq, void * elem, unsigned int in_num, unsigned int out_num)
{
    if (true) {
        _nocheck__trace_virtqueue_pop(vq, elem, in_num, out_num);
    }
}

#define TRACE_VIRTIO_QUEUE_NOTIFY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_QUEUE_NOTIFY) || \
    false)

static inline void _nocheck__trace_virtio_queue_notify(void * vdev, int n, void * vq)
{
    if (trace_event_get_state(TRACE_VIRTIO_QUEUE_NOTIFY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_queue_notify " "vdev %p n %d vq %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, n, vq);
    }
}

static inline void trace_virtio_queue_notify(void * vdev, int n, void * vq)
{
    if (true) {
        _nocheck__trace_virtio_queue_notify(vdev, n, vq);
    }
}

#define TRACE_VIRTIO_NOTIFY_IRQFD_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_NOTIFY_IRQFD) || \
    false)

static inline void _nocheck__trace_virtio_notify_irqfd(void * vdev, void * vq)
{
    if (trace_event_get_state(TRACE_VIRTIO_NOTIFY_IRQFD) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_notify_irqfd " "vdev %p vq %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, vq);
    }
}

static inline void trace_virtio_notify_irqfd(void * vdev, void * vq)
{
    if (true) {
        _nocheck__trace_virtio_notify_irqfd(vdev, vq);
    }
}

#define TRACE_VIRTIO_NOTIFY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_NOTIFY) || \
    false)

static inline void _nocheck__trace_virtio_notify(void * vdev, void * vq)
{
    if (trace_event_get_state(TRACE_VIRTIO_NOTIFY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_notify " "vdev %p vq %p" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, vq);
    }
}

static inline void trace_virtio_notify(void * vdev, void * vq)
{
    if (true) {
        _nocheck__trace_virtio_notify(vdev, vq);
    }
}

#define TRACE_VIRTIO_SET_STATUS_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_SET_STATUS) || \
    false)

static inline void _nocheck__trace_virtio_set_status(void * vdev, uint8_t val)
{
    if (trace_event_get_state(TRACE_VIRTIO_SET_STATUS) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_set_status " "vdev %p val %u" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , vdev, val);
    }
}

static inline void trace_virtio_set_status(void * vdev, uint8_t val)
{
    if (true) {
        _nocheck__trace_virtio_set_status(vdev, val);
    }
}

#define TRACE_VIRTIO_RNG_GUEST_NOT_READY_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_RNG_GUEST_NOT_READY) || \
    false)

static inline void _nocheck__trace_virtio_rng_guest_not_ready(void * rng)
{
    if (trace_event_get_state(TRACE_VIRTIO_RNG_GUEST_NOT_READY) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_rng_guest_not_ready " "rng %p: guest not ready" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , rng);
    }
}

static inline void trace_virtio_rng_guest_not_ready(void * rng)
{
    if (true) {
        _nocheck__trace_virtio_rng_guest_not_ready(rng);
    }
}

#define TRACE_VIRTIO_RNG_CPU_IS_STOPPED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_RNG_CPU_IS_STOPPED) || \
    false)

static inline void _nocheck__trace_virtio_rng_cpu_is_stopped(void * rng, int size)
{
    if (trace_event_get_state(TRACE_VIRTIO_RNG_CPU_IS_STOPPED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_rng_cpu_is_stopped " "rng %p: cpu is stopped, dropping %d bytes" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , rng, size);
    }
}

static inline void trace_virtio_rng_cpu_is_stopped(void * rng, int size)
{
    if (true) {
        _nocheck__trace_virtio_rng_cpu_is_stopped(rng, size);
    }
}

#define TRACE_VIRTIO_RNG_POPPED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_RNG_POPPED) || \
    false)

static inline void _nocheck__trace_virtio_rng_popped(void * rng)
{
    if (trace_event_get_state(TRACE_VIRTIO_RNG_POPPED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_rng_popped " "rng %p: elem popped" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , rng);
    }
}

static inline void trace_virtio_rng_popped(void * rng)
{
    if (true) {
        _nocheck__trace_virtio_rng_popped(rng);
    }
}

#define TRACE_VIRTIO_RNG_PUSHED_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_RNG_PUSHED) || \
    false)

static inline void _nocheck__trace_virtio_rng_pushed(void * rng, size_t len)
{
    if (trace_event_get_state(TRACE_VIRTIO_RNG_PUSHED) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_rng_pushed " "rng %p: %zd bytes pushed" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , rng, len);
    }
}

static inline void trace_virtio_rng_pushed(void * rng, size_t len)
{
    if (true) {
        _nocheck__trace_virtio_rng_pushed(rng, len);
    }
}

#define TRACE_VIRTIO_RNG_REQUEST_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_RNG_REQUEST) || \
    false)

static inline void _nocheck__trace_virtio_rng_request(void * rng, size_t size, unsigned quota)
{
    if (trace_event_get_state(TRACE_VIRTIO_RNG_REQUEST) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_rng_request " "rng %p: %zd bytes requested, %u bytes quota left" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , rng, size, quota);
    }
}

static inline void trace_virtio_rng_request(void * rng, size_t size, unsigned quota)
{
    if (true) {
        _nocheck__trace_virtio_rng_request(rng, size, quota);
    }
}

#define TRACE_VIRTIO_RNG_VM_STATE_CHANGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_RNG_VM_STATE_CHANGE) || \
    false)

static inline void _nocheck__trace_virtio_rng_vm_state_change(void * rng, int running, int state)
{
    if (trace_event_get_state(TRACE_VIRTIO_RNG_VM_STATE_CHANGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_rng_vm_state_change " "rng %p: state change to running %d state %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , rng, running, state);
    }
}

static inline void trace_virtio_rng_vm_state_change(void * rng, int running, int state)
{
    if (true) {
        _nocheck__trace_virtio_rng_vm_state_change(rng, running, state);
    }
}

#define TRACE_VIRTIO_BALLOON_BAD_ADDR_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BALLOON_BAD_ADDR) || \
    false)

static inline void _nocheck__trace_virtio_balloon_bad_addr(uint64_t gpa)
{
    if (trace_event_get_state(TRACE_VIRTIO_BALLOON_BAD_ADDR) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_balloon_bad_addr " "0x%"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , gpa);
    }
}

static inline void trace_virtio_balloon_bad_addr(uint64_t gpa)
{
    if (true) {
        _nocheck__trace_virtio_balloon_bad_addr(gpa);
    }
}

#define TRACE_VIRTIO_BALLOON_HANDLE_OUTPUT_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BALLOON_HANDLE_OUTPUT) || \
    false)

static inline void _nocheck__trace_virtio_balloon_handle_output(const char * name, uint64_t gpa)
{
    if (trace_event_get_state(TRACE_VIRTIO_BALLOON_HANDLE_OUTPUT) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_balloon_handle_output " "section name: %s gpa: 0x%"PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , name, gpa);
    }
}

static inline void trace_virtio_balloon_handle_output(const char * name, uint64_t gpa)
{
    if (true) {
        _nocheck__trace_virtio_balloon_handle_output(name, gpa);
    }
}

#define TRACE_VIRTIO_BALLOON_GET_CONFIG_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BALLOON_GET_CONFIG) || \
    false)

static inline void _nocheck__trace_virtio_balloon_get_config(uint32_t num_pages, uint32_t actual)
{
    if (trace_event_get_state(TRACE_VIRTIO_BALLOON_GET_CONFIG) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_balloon_get_config " "num_pages: %d actual: %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , num_pages, actual);
    }
}

static inline void trace_virtio_balloon_get_config(uint32_t num_pages, uint32_t actual)
{
    if (true) {
        _nocheck__trace_virtio_balloon_get_config(num_pages, actual);
    }
}

#define TRACE_VIRTIO_BALLOON_SET_CONFIG_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BALLOON_SET_CONFIG) || \
    false)

static inline void _nocheck__trace_virtio_balloon_set_config(uint32_t actual, uint32_t oldactual)
{
    if (trace_event_get_state(TRACE_VIRTIO_BALLOON_SET_CONFIG) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_balloon_set_config " "actual: %d oldactual: %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , actual, oldactual);
    }
}

static inline void trace_virtio_balloon_set_config(uint32_t actual, uint32_t oldactual)
{
    if (true) {
        _nocheck__trace_virtio_balloon_set_config(actual, oldactual);
    }
}

#define TRACE_VIRTIO_BALLOON_TO_TARGET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_BALLOON_TO_TARGET) || \
    false)

static inline void _nocheck__trace_virtio_balloon_to_target(uint64_t target, uint32_t num_pages)
{
    if (trace_event_get_state(TRACE_VIRTIO_BALLOON_TO_TARGET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_balloon_to_target " "balloon target: 0x%"PRIx64" num_pages: %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , target, num_pages);
    }
}

static inline void trace_virtio_balloon_to_target(uint64_t target, uint32_t num_pages)
{
    if (true) {
        _nocheck__trace_virtio_balloon_to_target(target, num_pages);
    }
}

#define TRACE_VIRTIO_MMIO_READ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_MMIO_READ) || \
    false)

static inline void _nocheck__trace_virtio_mmio_read(uint64_t offset)
{
    if (trace_event_get_state(TRACE_VIRTIO_MMIO_READ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_mmio_read " "virtio_mmio_read offset 0x%" PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset);
    }
}

static inline void trace_virtio_mmio_read(uint64_t offset)
{
    if (true) {
        _nocheck__trace_virtio_mmio_read(offset);
    }
}

#define TRACE_VIRTIO_MMIO_WRITE_OFFSET_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_MMIO_WRITE_OFFSET) || \
    false)

static inline void _nocheck__trace_virtio_mmio_write_offset(uint64_t offset, uint64_t value)
{
    if (trace_event_get_state(TRACE_VIRTIO_MMIO_WRITE_OFFSET) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_mmio_write_offset " "virtio_mmio_write offset 0x%" PRIx64 " value 0x%" PRIx64 "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , offset, value);
    }
}

static inline void trace_virtio_mmio_write_offset(uint64_t offset, uint64_t value)
{
    if (true) {
        _nocheck__trace_virtio_mmio_write_offset(offset, value);
    }
}

#define TRACE_VIRTIO_MMIO_GUEST_PAGE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_MMIO_GUEST_PAGE) || \
    false)

static inline void _nocheck__trace_virtio_mmio_guest_page(uint64_t size, int shift)
{
    if (trace_event_get_state(TRACE_VIRTIO_MMIO_GUEST_PAGE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_mmio_guest_page " "guest page size 0x%" PRIx64 " shift %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , size, shift);
    }
}

static inline void trace_virtio_mmio_guest_page(uint64_t size, int shift)
{
    if (true) {
        _nocheck__trace_virtio_mmio_guest_page(size, shift);
    }
}

#define TRACE_VIRTIO_MMIO_QUEUE_WRITE_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_MMIO_QUEUE_WRITE) || \
    false)

static inline void _nocheck__trace_virtio_mmio_queue_write(uint64_t value, int max_size)
{
    if (trace_event_get_state(TRACE_VIRTIO_MMIO_QUEUE_WRITE) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_mmio_queue_write " "mmio_queue write 0x%" PRIx64 " max %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , value, max_size);
    }
}

static inline void trace_virtio_mmio_queue_write(uint64_t value, int max_size)
{
    if (true) {
        _nocheck__trace_virtio_mmio_queue_write(value, max_size);
    }
}

#define TRACE_VIRTIO_MMIO_SETTING_IRQ_BACKEND_DSTATE() ( \
    trace_event_get_state_dynamic_by_id(TRACE_VIRTIO_MMIO_SETTING_IRQ) || \
    false)

static inline void _nocheck__trace_virtio_mmio_setting_irq(int level)
{
    if (trace_event_get_state(TRACE_VIRTIO_MMIO_SETTING_IRQ) && qemu_loglevel_mask(LOG_TRACE)) {
        struct timeval _now;
        gettimeofday(&_now, NULL);
        qemu_log("%d@%zu.%06zu:virtio_mmio_setting_irq " "virtio_mmio setting IRQ %d" "\n",
                 qemu_get_thread_id(),
                 (size_t)_now.tv_sec, (size_t)_now.tv_usec
                 , level);
    }
}

static inline void trace_virtio_mmio_setting_irq(int level)
{
    if (true) {
        _nocheck__trace_virtio_mmio_setting_irq(level);
    }
}
#endif /* TRACE_HW_VIRTIO_GENERATED_TRACERS_H */
